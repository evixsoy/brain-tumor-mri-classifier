{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for tensorflow\n"
     ]
    }
   ],
   "source": [
    "%pip install split-folders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#check for duplicate pictures\n",
    "import os\n",
    "import hashlib\n",
    "\n",
    "hashes = {}\n",
    "\n",
    "for type_folder in os.listdir('dataset-classification'):\n",
    "    for tumor_folder in os.listdir(f'classification/{type_folder}'):\n",
    "        for file in os.listdir(f'classification/{type_folder}/{tumor_folder}'):\n",
    "            filepath = f'classification/{type_folder}/{tumor_folder}/{file}'\n",
    "            with open(filepath, 'rb') as f:\n",
    "                file_hash = hashlib.md5(f.read()).hexdigest()\n",
    "                if file_hash not in hashes:\n",
    "                    hashes[file_hash] = []\n",
    "                \n",
    "                hashes[file_hash].append(filepath)\n",
    "#delete duplicates\n",
    "count = 0\n",
    "for file_hash, path_list in hashes.items():\n",
    "    while len(path_list) > 1: \n",
    "        to_delete = path_list.pop()\n",
    "        os.remove(to_delete)\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: [['glioma_tumor', 2328], ['meningioma_tumor', 1635], ['no_tumor', 1708], ['pituitary_tumor', 1776]]\n"
     ]
    }
   ],
   "source": [
    "#count dataset images\n",
    "def count_images(path: str)-> str:\n",
    "    result = {}\n",
    "    for type_folder in os.listdir(f'{path}'):\n",
    "        temp = []\n",
    "        for tumor_folder in os.listdir(f'{path}/{type_folder}'):\n",
    "            count = 0\n",
    "            for file in os.listdir(f'{path}/{type_folder}/{tumor_folder}'):\n",
    "                count+=1\n",
    "            temp.append(list([tumor_folder,count]))\n",
    "        result[type_folder] = temp\n",
    "\n",
    "    for i in result.keys():\n",
    "        print(f'{i}: {result[i]}')\n",
    "count_images('dataset-classification')\n",
    "#with duplicates:\n",
    "# Testing: [['glioma_tumor', 400], ['meningioma_tumor', 421], ['no_tumor', 510], ['pituitary_tumor', 374]]\n",
    "# Training: [['glioma_tumor', 2147], ['meningioma_tumor', 2161], ['no_tumor', 1990], ['pituitary_tumor', 2284]]\n",
    "# Testing count: 1705\n",
    "# Training count: 8582"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge testing and training folders (unmerged from original dataset)\n",
    "import shutil\n",
    "if os.path.exists(f'dataset-classification/Testing'):\n",
    "    for tumor_folder in os.listdir(f'dataset-classification/Testing'):\n",
    "        for file in os.listdir(f'dataset-classification/Testing/{tumor_folder}'):\n",
    "            shutil.move(f'dataset-classification/Testing/{tumor_folder}/{file}', f'dataset-classification/Training/{tumor_folder}/{file}')\n",
    "    shutil.rmtree('dataset-classification/Testing')\n",
    "\n",
    "#split testing folder into testing,validation folders\n",
    "import splitfolders\n",
    "\n",
    "input_folder = os.path.join('dataset-classification/Training')\n",
    "output_folder = os.path.join('dataset_split_classification')\n",
    "split_ratio = (0.7,0.15,0.15)\n",
    "\n",
    "splitfolders.ratio(\n",
    "    input_folder,\n",
    "    output = output_folder,\n",
    "    seed = 12,\n",
    "    ratio = split_ratio,\n",
    "    group_prefix= None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: [['glioma_tumor', 350], ['meningioma_tumor', 246], ['no_tumor', 257], ['pituitary_tumor', 267]]\n",
      "train: [['glioma_tumor', 1629], ['meningioma_tumor', 1144], ['no_tumor', 1195], ['pituitary_tumor', 1243]]\n",
      "val: [['glioma_tumor', 349], ['meningioma_tumor', 245], ['no_tumor', 256], ['pituitary_tumor', 266]]\n"
     ]
    }
   ],
   "source": [
    "count_images('dataset_split_classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#balance dataset\n",
    "import random\n",
    "balanced_values = {\n",
    "    'train' : 1140,\n",
    "    'val' : 245,\n",
    "    'test' : 256\n",
    "}\n",
    "for type_folder in os.listdir('dataset_split_classification'):\n",
    "    for tumor_folder in os.listdir(f'dataset_split_classification/{type_folder}'):\n",
    "        while len(os.listdir(f'dataset_split_classification/{type_folder}/{tumor_folder}')) > balanced_values[type_folder]:\n",
    "                files = os.listdir(f'dataset_split_classification/{type_folder}/{tumor_folder}')\n",
    "                os.remove(f'dataset_split_classification/{type_folder}/{tumor_folder}/{random.choice(files)}')\n",
    "\n",
    "#todo pridat ze cisla balanced_values neni hardcoded ale vytahne to nejnizsi cislo souboru ve slozce + celkove vsechny path nebudou tak hardcoded napr dataset_split/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: [['glioma_tumor', 256], ['meningioma_tumor', 246], ['no_tumor', 256], ['pituitary_tumor', 256]]\n",
      "train: [['glioma_tumor', 1140], ['meningioma_tumor', 1140], ['no_tumor', 1140], ['pituitary_tumor', 1140]]\n",
      "val: [['glioma_tumor', 245], ['meningioma_tumor', 245], ['no_tumor', 245], ['pituitary_tumor', 245]]\n"
     ]
    }
   ],
   "source": [
    "count_images('dataset_split_classification')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
